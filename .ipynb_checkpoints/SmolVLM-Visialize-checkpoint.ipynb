{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "616f0ed9-9ebc-445c-946a-5d2da1bf1271",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using device: mps\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "from PIL import Image\n",
    "from transformers import AutoProcessor, AutoModelForVision2Seq\n",
    "\n",
    "# ‚úÖ Detect device (Use MPS for Mac)\n",
    "DEVICE = \"mps\" if torch.backends.mps.is_available() else \"cpu\"\n",
    "print(f\"Using device: {DEVICE}\")\n",
    "\n",
    "# ‚úÖ Load a single image from local disk (Change file path as needed)\n",
    "image_path = \"./image.jpg\"  # Update with your actual path\n",
    "image = Image.open(image_path).convert(\"RGB\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "2a9b77ad-dafd-499d-b02a-7580e33d5997",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6b00c15ea4b64bab9b3a50fdd6e75109",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "processor_config.json:   0%|          | 0.00/68.0 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8b5492cbfe854c8f8c58e754edf46cf0",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "chat_template.json:   0%|          | 0.00/429 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d340cf3a754d44fbab9658433c914984",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "preprocessor_config.json:   0%|          | 0.00/486 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7199130092f54ed3b05d109f090389c0",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "tokenizer_config.json:   0%|          | 0.00/4.48k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ed0e25414479496291411595d38171aa",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "vocab.json:   0%|          | 0.00/801k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ae2d543f78954ac3abb48156c59e51b5",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "merges.txt:   0%|          | 0.00/466k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6f04196c699645259249a1d01021f0ff",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "tokenizer.json:   0%|          | 0.00/3.52M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3517ea8b1b8c4289b0ba823808b8ecdd",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "added_tokens.json:   0%|          | 0.00/92.0 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6c9ce99a3f01472ea2cd31162398a256",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "special_tokens_map.json:   0%|          | 0.00/1.07k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "45242476fb84489abb84356bb9cb4ffc",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "config.json:   0%|          | 0.00/7.32k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ea12d6332560433dbe0cea38470c7184",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "model.safetensors:   0%|          | 0.00/4.49G [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f4aa165ccf52484baadc531ee5dca1d4",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "generation_config.json:   0%|          | 0.00/136 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ Model & Processor Loaded!\n"
     ]
    }
   ],
   "source": [
    "# ‚úÖ Initialize processor and model\n",
    "processor = AutoProcessor.from_pretrained(\"HuggingFaceTB/SmolVLM-Instruct\")\n",
    "model = AutoModelForVision2Seq.from_pretrained(\n",
    "    \"HuggingFaceTB/SmolVLM-Instruct\",\n",
    "    torch_dtype=torch.float16,  # Use float16 for efficiency on Mac\n",
    "    attn_implementation=\"eager\",  # Required for Transformers 5.0+\n",
    ").to(DEVICE)\n",
    "\n",
    "print(\"‚úÖ Model & Processor Loaded!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "9383762c-dbee-4948-9a6d-831616530b82",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ Inputs processed, running inference...\n"
     ]
    }
   ],
   "source": [
    "# ‚úÖ Prepare input prompt\n",
    "messages = [\n",
    "    {\n",
    "        \"role\": \"user\",\n",
    "        \"content\": [\n",
    "            {\"type\": \"image\"},\n",
    "            {\"type\": \"text\", \"text\": \"Can you describe the image in detail?\"}\n",
    "        ]\n",
    "    },\n",
    "]\n",
    "\n",
    "# ‚úÖ Tokenize text prompt\n",
    "prompt = processor.apply_chat_template(messages, add_generation_prompt=True)\n",
    "\n",
    "# ‚úÖ Preprocess image and text\n",
    "inputs = processor(\n",
    "    text=prompt,\n",
    "    images=[image],\n",
    "    return_tensors=\"pt\"\n",
    ").to(DEVICE)\n",
    "\n",
    "print(\"‚úÖ Inputs processed, running inference...\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "56a5f3ed-2381-411b-b31c-b07bb8080c89",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "üìù Model Response:\n",
      "\n",
      "User:<image>Can you describe the image in detail?\n",
      "Assistant: The image features a group of five people sitting on a concrete bench outdoors. The individuals are arranged in a casual manner, with two women seated on the left and right sides, and three men in the middle. The people are dressed in casual attire, with the women wearing jeans and the men wearing a mix of jeans and a button-down shirt.\n",
      "\n",
      "The background of the image is blurred, focusing attention on the individuals in the foreground. The setting appears to be an outdoor area, possibly a park or a public space, given the presence of trees and the natural light. The sky is clear, suggesting it is a sunny day.\n",
      "\n",
      "The individuals are all smiling, indicating a positive and friendly atmosphere. The expressions suggest a sense of camaraderie and enjoyment among the group.\n",
      "\n",
      "Here is a detailed description of each person:\n",
      "\n",
      "1. **Left Side**:\n",
      "   - **Person 1**: This individual is a young woman with long, dark, wavy hair. She is wearing a red, collared, button-down shirt and blue jeans. She is sitting with her left hand resting on her knee and her right arm around the shoulder of the person next to her.\n",
      "\n",
      "2. **Middle**:\n",
      "   - **Person 2**: This individual is a young man with short, dark hair. He is wearing a blue, collared, button-down shirt and dark jeans. He is sitting with his left hand on his knee and his right arm around the shoulder of the person next to him.\n",
      "\n",
      "3. **Middle**:\n",
      "   - **Person 3**: This individual is a young woman with long, dark, wavy hair. She is wearing a white, long-sleeved shirt and dark jeans. She is sitting with her left hand on her knee and her right arm around the shoulder of the person next to her.\n",
      "\n",
      "4. **Right Side**:\n",
      "   - **Person 4**: This individual is a young man with short, dark hair. He is wearing a blue, collared, button-down shirt and dark jeans. He is sitting with his left hand on his knee and his right arm around the shoulder of the person next to him.\n",
      "\n",
      "5. **Right Side**:\n",
      "   - **Person 5**: This individual is a young man with short, dark hair. He is wearing a black polo shirt and dark jeans. He is sitting with his left hand on his knee and his right arm around the shoulder of the person next to him\n"
     ]
    }
   ],
   "source": [
    "# ‚úÖ Generate output\n",
    "with torch.no_grad():\n",
    "    generated_ids = model.generate(**inputs, max_new_tokens=500)\n",
    "\n",
    "# ‚úÖ Decode generated text\n",
    "generated_texts = processor.batch_decode(generated_ids, skip_special_tokens=True)\n",
    "\n",
    "# ‚úÖ Display output\n",
    "print(\"\\nüìù Model Response:\\n\")\n",
    "print(generated_texts[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "45f653ba-ef51-4ea1-a978-e03f6a177457",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:base] *",
   "language": "python",
   "name": "conda-base-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
