{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "b2989514-7ed7-41d5-b3b5-6f0384f821bb",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "os.environ[\"OPENAI_API_KEY\"] = \"\"  # Replace with your actual key"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "d2525d45-4fb3-49ed-9189-de179fa3f913",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Title: Partha Sai Guttikonda\n"
     ]
    }
   ],
   "source": [
    "import asyncio\n",
    "from playwright.async_api import async_playwright\n",
    "\n",
    "async def run_playwright_async():\n",
    "    async with async_playwright() as p:\n",
    "        browser = await p.chromium.launch(headless=True)\n",
    "        page = await browser.new_page()\n",
    "        await page.goto(\"https://guttikondaparthasai.info/\")\n",
    "        \n",
    "        # Screenshot\n",
    "        await page.screenshot(path=\"example_screenshot.png\")\n",
    "        print(\"Title:\", await page.title())\n",
    "\n",
    "        await browser.close()\n",
    "\n",
    "# Run it\n",
    "await run_playwright_async()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "id": "60541334-9d0e-445b-a517-684cf78c362f",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/w5/81rp1d0x34nd8g9c4y0lbncc0000gn/T/ipykernel_64374/1883971777.py:14: LangChainDeprecationWarning: LangChain agents will continue to be supported, but it is recommended for new use cases to be built with LangGraph. LangGraph offers a more flexible and full-featured framework for building agents, including support for tool-calling, persistence of state, and human-in-the-loop workflows. For details, refer to the `LangGraph documentation <https://langchain-ai.github.io/langgraph/>`_ as well as guides for `Migrating from AgentExecutor <https://python.langchain.com/docs/how_to/migrate_agent/>`_ and LangGraph's `Pre-built ReAct agent <https://langchain-ai.github.io/langgraph/how-tos/create-react-agent/>`_.\n",
      "  agent = initialize_agent(\n",
      "/var/folders/w5/81rp1d0x34nd8g9c4y0lbncc0000gn/T/ipykernel_64374/1883971777.py:22: LangChainDeprecationWarning: The method `Chain.run` was deprecated in langchain 0.1.0 and will be removed in 1.0. Use :meth:`~invoke` instead.\n",
      "  response = agent.run(\"What's the latest news about LLaMA 3?\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\u001b[1m> Entering new AgentExecutor chain...\u001b[0m\n",
      "\u001b[32;1m\u001b[1;3mI should search for the latest news about LLaMA 3 to provide an accurate answer.\n",
      "Action: duckduckgo_search\n",
      "Action Input: LLaMA 3 latest news\u001b[0m\n",
      "Observation: \u001b[36;1m\u001b[1;3mOur new 8B and 70B parameter Llama 3 models are a major leap over Llama 2 and establish a new state-of-the-art for LLM models at those scales. Thanks to improvements in pretraining and post-training, our pretrained and instruction-fine-tuned models are the best models existing today at the 8B and 70B parameter scale. The new Llama 3.3 70B model has just dropped ‚Äî here's why it's a big deal. Features. ... Get instant access to breaking news, the hottest reviews, great deals and helpful tips. Bringing open intelligence to all, our latest models expand context length to 128K, add support across eight languages, and include Llama 3.1 405B‚Äîthe first frontier-level open source AI model. Llama 3.1 405B is in a class of its own, with unmatched flexibility, control, and state-of-the-art capabilities that rival the best closed source models. Meta released its most capable open source LLM, Llama 3, which outperforms in most benchmarks. ... Google, AWS, 01.ai, and other LLM players are generating headlines by releasing new and more ... Llama 3.3 70B, which is available for download from the AI dev platform Hugging Face and other sources, including the official Llama website, is Meta's latest play to dominate the AI field with ...\u001b[0m\n",
      "Thought:\u001b[32;1m\u001b[1;3mI should continue searching for more specific details about LLaMA 3.3 70B.\n",
      "Action: duckduckgo_search\n",
      "Action Input: LLaMA 3.3 70B details\u001b[0m\n",
      "Observation: \u001b[36;1m\u001b[1;3mAnd to close out the year, we released Llama 3.3 70B, a text-only model that offers similar performance as the 3.1 405B at a fraction of the serving cost. As Meta Founder & CEO Mark Zuckerberg shared , Llama has quickly become the most adopted model, with more than 650 million downloads of Llama and its derivatives, twice as many downloads as ... On the more challenging MMLU PRO (5-shot, CoT) benchmark, Llama 3.3 improves over Llama 3.1 70B with a score of 68.9, but it remains behind both Llama 3.1 405B (73.4) and Claude 3.5 Sonnet (77.8). For reasoning tasks, Llama 3.3 scores 50.5 on GPQA Diamond (0-shot, CoT), a slight improvement over Llama 3.1 70B (48.0). While this places it behind ... This repository contains two versions of Llama-3.3-70B-Instruct, for use with transformers and with the original llama codebase. Use with transformers Starting with transformers >= 4.45.0 onward, you can run conversational inference using the Transformers pipeline abstraction or by leveraging the Auto classes with the generate() function. The Meta Llama 3.3 multilingual large language model (LLM) is a pretrained and instruction tuned generative model in 70B (text in/text out). The Llama 3.3 instruction tuned text only model is optimized for multilingual dialogue use cases and outperforms many of the available open source and closed chat models on common industry benchmarks. LLaMA 3.3 70B: Released by Meta, LLaMA 3.3 70B is optimized for multilingual dialogue and instruction-following tasks. It performs well in coding assistance, multilingual communication, and is efficient and capable of using the \"Agentic Search\" feature. Details about the hosting and use of these models is found on TritonGPT Large Language Models.\u001b[0m\n",
      "Thought:\u001b[32;1m\u001b[1;3mI have gathered enough information about LLaMA 3.3 70B.\n",
      "Final Answer: The latest news about LLaMA 3 is the release of LLaMA 3.3 70B, a text-only model optimized for multilingual dialogue and instruction-following tasks.\u001b[0m\n",
      "\n",
      "\u001b[1m> Finished chain.\u001b[0m\n",
      "The latest news about LLaMA 3 is the release of LLaMA 3.3 70B, a text-only model optimized for multilingual dialogue and instruction-following tasks.\n"
     ]
    }
   ],
   "source": [
    "from langchain.chat_models import ChatOpenAI\n",
    "from langchain.agents import initialize_agent, AgentType\n",
    "from langchain.tools import DuckDuckGoSearchRun\n",
    "\n",
    "# LLM\n",
    "llm = ChatOpenAI(temperature=0, model=\"gpt-3.5-turbo\")\n",
    "\n",
    "# Tool\n",
    "search_tool = DuckDuckGoSearchRun()\n",
    "\n",
    "# Agent with search capability\n",
    "tools = [search_tool]\n",
    "\n",
    "agent = initialize_agent(\n",
    "    tools=tools,\n",
    "    llm=llm,\n",
    "    agent=AgentType.ZERO_SHOT_REACT_DESCRIPTION,\n",
    "    verbose=True\n",
    ")\n",
    "\n",
    "# Run the agent\n",
    "response = agent.run(\"What's the latest news about LLaMA 3?\")\n",
    "print(response)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "id": "99a60f36-8464-4588-be9e-cb5b994cbbe6",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.tools import tool\n",
    "from playwright.async_api import async_playwright\n",
    "import asyncio\n",
    "\n",
    "@tool\n",
    "async def browse_and_screenshot(url: str) -> str:\n",
    "    \"\"\"Visit a URL and take a screenshot.\"\"\"\n",
    "    async with async_playwright() as p:\n",
    "        browser = await p.chromium.launch(headless=True)\n",
    "        page = await browser.new_page()\n",
    "        await page.goto(url)\n",
    "        screenshot_path = \"screenshot.png\"\n",
    "        await page.screenshot(path=screenshot_path)\n",
    "        await browser.close()\n",
    "        return f\"Screenshot saved to {screenshot_path}\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "id": "396bee73-9e4b-4186-b4a8-32134da9f3d4",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.agents import initialize_agent, AgentType\n",
    "from langchain.chat_models import ChatOpenAI\n",
    "from langchain.tools import DuckDuckGoSearchRun\n",
    "\n",
    "# LLM\n",
    "llm = ChatOpenAI(temperature=0, model=\"gpt-3.5-turbo\")\n",
    "\n",
    "# Tools\n",
    "search = DuckDuckGoSearchRun()\n",
    "tools = [search, browse_and_screenshot]\n",
    "\n",
    "# Async agent initialization\n",
    "agent = initialize_agent(\n",
    "    tools=tools,\n",
    "    llm=llm,\n",
    "    agent=AgentType.OPENAI_FUNCTIONS,  # supports async tools!\n",
    "    verbose=True\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "id": "e7742174-28fc-4ff9-a05c-996afb243d76",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\u001b[1m> Entering new AgentExecutor chain...\u001b[0m\n",
      "\u001b[32;1m\u001b[1;3m\n",
      "Invoking: `duckduckgo_search` with `{'query': 'Partha Sai Guttikonda'}`\n",
      "\n",
      "\n",
      "\u001b[0m\u001b[36;1m\u001b[1;3mPublished 5/14/2024 by Jai Prakash Veerla, Partha Sai Guttikonda, Amir Hajighasemi, Jillur Rahman Saurav, Aarti Darji, Cody T. Reynolds, Mohamed Mohamed and 3 more... SpatialVisVR: An Immersive, Multiplexed Medical Image Viewer With Contextual Similar-Patient Search Published 5/9/2024 by Poojitha Thota, Jai Prakash Veerla, Partha Sai Guttikonda, Mohammad S. Nasr, Shirin Nilizadeh, Jacob M. Luber Demonstration of an Adversarial Attack Against a Multimodal Vision Language Model for Pathology Imaging We found 7 Sai Guttikonda's profiles > Get contact information, phone numbers, home addresses, age, background check, photos, and other public records [Updated: Jan 23, 2025]. Partha Sai Guttikonda. SSL auto-renew inside Nginx docker container. About the config crontab inside the Nginx container. Oct 26, 2021. 1. Oct 26, 2021. 1. G√∂khan ≈ûeng√ºn. SSL Sertifika Tipleri ... Sai Balaji, Christopher Sun, Anaiy Somalwar: Improving Machine Learning Based Sepsis Diagnosis Using Heart Rate Variability. 1-8. view. electronic edition via DOI; ... Jai Prakash Veerla, Partha Sai Guttikonda, Amir Hajighasemi, Jillur Rahman Saurav, Aarti Darji, Cody T. Reynolds, ...\u001b[0m\u001b[32;1m\u001b[1;3m\n",
      "Invoking: `browse_and_screenshot` with `{'url': 'https://guttikondaparthasai.info/'}`\n",
      "\n",
      "\n",
      "\u001b[0m\u001b[33;1m\u001b[1;3mScreenshot saved to screenshot.png\u001b[0m\u001b[32;1m\u001b[1;3mI have captured a complete page screenshot of Partha Sai Guttikonda's portfolio page. You can view the screenshot [here](sandbox:/screenshot.png).\u001b[0m\n",
      "\n",
      "\u001b[1m> Finished chain.\u001b[0m\n",
      "I have captured a complete page screenshot of Partha Sai Guttikonda's portfolio page. You can view the screenshot [here](sandbox:/screenshot.png).\n"
     ]
    }
   ],
   "source": [
    "async def main():\n",
    "    result = await agent.arun(\"Search for the Partha Sai Guttikonda, goto his portfolio page(https://guttikondaparthasai.info/) wait till it loads completely(10 sec) and capture complete page screenshot.\")\n",
    "    print(result)\n",
    "\n",
    "await main()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f86f5791-79e9-47e5-9eba-d66bba66d3bc",
   "metadata": {},
   "source": [
    "# Full Flow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "id": "a9c72b57-c7fb-4e3a-bd03-0804ec825021",
   "metadata": {},
   "outputs": [],
   "source": [
    "# -----------------------------\n",
    "# üì¶ Step 1: Imports & Setup\n",
    "# -----------------------------\n",
    "import os\n",
    "import json\n",
    "import re\n",
    "import requests\n",
    "from langchain.prompts import PromptTemplate\n",
    "from langchain.chains import LLMChain\n",
    "from langchain.chat_models import ChatOpenAI"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "id": "3bf2212b-983a-4927-a455-2d363f885097",
   "metadata": {},
   "outputs": [],
   "source": [
    "# üß† LLM setup\n",
    "llm = ChatOpenAI(model=\"gpt-3.5-turbo\", temperature=0)\n",
    "\n",
    "# -----------------------------\n",
    "# üß† Step 2: Prompt Template\n",
    "# -----------------------------\n",
    "mcp_prompt = PromptTemplate.from_template(\"\"\"\n",
    "You're a browser automation assistant. Convert the following task into a **pure JSON array** of Playwright MCP `actions`.\n",
    "\n",
    "TASK: {task}\n",
    "\n",
    "RESPONSE FORMAT (must match):\n",
    "[\n",
    "  {{ \"type\": \"goto\", \"url\": \"...\" }},\n",
    "  {{ \"type\": \"wait\", \"time\": ... }},\n",
    "  ...\n",
    "]\n",
    "Return only the JSON. No markdown. No explanation.\n",
    "\"\"\")\n",
    "\n",
    "mcp_chain = LLMChain(llm=llm, prompt=mcp_prompt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "id": "fca0357c-504f-4614-836e-a3d284266409",
   "metadata": {},
   "outputs": [],
   "source": [
    "# -----------------------------\n",
    "# üí¨ Step 3: User Task\n",
    "# -----------------------------\n",
    "task_prompt = (\n",
    "    \"Go to Partha Sai Guttikonda's portfolio page at https://guttikondaparthasai.info/, \"\n",
    "    \"wait for 10 seconds, and take a full-page screenshot named 'partha_mcp_screenshot.png'.\"\n",
    ")\n",
    "\n",
    "generated = mcp_chain.run(task=task_prompt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "id": "a7c8505c-56a2-4cea-acfd-0653f1c0cbe7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# -----------------------------\n",
    "# üßº Step 4: Extract JSON from LLM Output\n",
    "# -----------------------------\n",
    "match = re.search(r\"\\[\\s*{.*?}\\s*\\]\", generated, re.DOTALL)\n",
    "if match:\n",
    "    cleaned_json = match.group(0)\n",
    "    try:\n",
    "        actions = json.loads(cleaned_json)\n",
    "    except json.JSONDecodeError as e:\n",
    "        print(\"JSON Decode Error:\", e)\n",
    "        print(\"Original Output:\\n\", generated)\n",
    "        raise\n",
    "else:\n",
    "    print(\"‚ùå Failed to parse JSON. Full LLM output:\\n\", generated)\n",
    "    raise ValueError(\"No valid JSON array found.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "id": "df8e3fd8-9cef-4686-918f-4336a36280c4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ MCP Server Response:\n",
      "‚ùå MCP Server Error: Expecting value: line 1 column 1 (char 0)\n"
     ]
    }
   ],
   "source": [
    "# -----------------------------\n",
    "# üåê Step 5: Send to MCP Server\n",
    "# -----------------------------\n",
    "MCP_URL = \"http://localhost:8931/api/command\"  # make sure MCP is running\n",
    "\n",
    "payload = {\"actions\": actions}\n",
    "\n",
    "try:\n",
    "    res = requests.post(MCP_URL, json=payload)\n",
    "    print(\"‚úÖ MCP Server Response:\")\n",
    "    print(res.json())\n",
    "except Exception as e:\n",
    "    print(\"‚ùå MCP Server Error:\", e)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "id": "cfe8358a-f415-4000-8fa0-4d4f80096eb6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'actions': [{'type': 'goto', 'url': 'https://guttikondaparthasai.info/'},\n",
       "  {'type': 'wait', 'time': 10000},\n",
       "  {'type': 'screenshot', 'path': 'partha_mcp_screenshot.png'}]}"
      ]
     },
     "execution_count": 127,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "payload"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1eb067c1-15e9-4e24-864d-51f0b797c0a4",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:base] *",
   "language": "python",
   "name": "conda-base-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
